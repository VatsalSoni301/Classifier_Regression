{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score,confusion_matrix,classification_report,accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"AdmissionDataset/data.csv\")\n",
    "threshold = 0.5\n",
    "learning_rate = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Chance of Admit ','Serial No.'],axis=1)\n",
    "Y = df['Chance of Admit ']\n",
    "Y = list(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(Y)):\n",
    "    if float(Y[i])>=threshold:\n",
    "        Y[i]=1\n",
    "    else:\n",
    "        Y[i]=0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = pd.DataFrame({'Chance of Admit ':Y})\n",
    "Y = Y['Chance of Admit ']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "# Y_train = (Y_train - Y_train.mean())/Y_train.std()\n",
    "X_test = (X_test - X_test.mean())/X_test.std()\n",
    "# Y_test = (Y_test - Y_test.mean())/Y_test.std()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n",
      "0.9333333333333333\n",
      "[[ 3  4]\n",
      " [ 2 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.43      0.50         7\n",
      "           1       0.95      0.98      0.96        83\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        90\n",
      "   macro avg       0.78      0.70      0.73        90\n",
      "weighted avg       0.93      0.93      0.93        90\n",
      "\n",
      "93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(solver='lbfgs',max_iter=iterations)\n",
    "lr.fit(X_train, Y_train) \n",
    "y_pred = lr.predict(X_test)\n",
    "score = lr.score(X_test,Y_test)\n",
    "print(score)\n",
    "print((Y_test == y_pred).mean())\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = Y_train['Chance of Admit ']\n",
    "# print(X_train.shape)\n",
    "X_train = pd.concat([X_train,Y_train],axis=1)\n",
    "ones = np.ones([X_train.shape[0],1])\n",
    "Y_train = X_train.iloc[:,7:8].values\n",
    "X_train = X_train.iloc[:,0:7]\n",
    "X_train = np.concatenate((ones,X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# theta = np.zeros(8) # 7 is the number of features\n",
    "theta = np.zeros([1,8])\n",
    "# theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(X_train,Y_train,theta,learning_rate,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(np.dot(X_train,theta.T))\n",
    "        theta = theta - (learning_rate/len(X_train)) * np.sum(X_train * (h - Y_train), axis=0)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gradient_decent(X_train,Y_train,theta,learning_rate,iterations)\n",
    "g = g[0]\n",
    "# g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for index,rows in X_test.iterrows():\n",
    "    y = 0\n",
    "    rows = list(rows)\n",
    "    for i in range(len(rows)):\n",
    "        y = y + rows[i]*g[i+1]\n",
    "    y = y + g[0]\n",
    "#     print(y)\n",
    "    if y >= threshold:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94.44444444444444\n",
      "[[ 3  4]\n",
      " [ 1 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.43      0.55         7\n",
      "           1       0.95      0.99      0.97        83\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        90\n",
      "   macro avg       0.85      0.71      0.76        90\n",
      "weighted avg       0.94      0.94      0.94        90\n",
      "\n",
      "94.44444444444444\n"
     ]
    }
   ],
   "source": [
    "print((y_pred == Y_test).mean()*100)\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test, y_pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
