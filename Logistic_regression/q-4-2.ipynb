{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score,confusion_matrix,classification_report,accuracy_score\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"AdmissionDataset/data.csv\")\n",
    "threshold = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = df['Chance of Admit ']\n",
    "Y = list(Y)\n",
    "for i in range(len(Y)):\n",
    "    if Y[i]>=threshold:\n",
    "        Y[i]=1\n",
    "    else:\n",
    "        Y[i]=0\n",
    "Y = pd.DataFrame({'Chance of Admit ':Y})\n",
    "Y = Y['Chance of Admit ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Chance of Admit ','Serial No.'],axis=1)\n",
    "# Y = df['Chance of Admit ']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "X_train_knn = copy.deepcopy(X_train)\n",
    "Y_train_knn = copy.deepcopy(Y_train)\n",
    "X_test_knn = copy.deepcopy(X_test)\n",
    "Y_test_knn = copy.deepcopy(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "X_test = (X_test - X_test.mean())/X_test.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train,Y_train],axis=1)\n",
    "ones = np.ones([X_train.shape[0],1])\n",
    "Y_train = X_train.iloc[:,7:8].values\n",
    "X_train = X_train.iloc[:,0:7]\n",
    "X_train = np.concatenate((ones,X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "# theta = np.zeros(8) # 7 is the number of features\n",
    "theta = np.zeros([1,8])\n",
    "# theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent(X_train,Y_train,theta,learning_rate,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        h = sigmoid(np.dot(X_train,theta.T))\n",
    "        theta = theta - (learning_rate/len(X_train)) * np.sum(X_train * (h - Y_train), axis=0)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gradient_decent(X_train,Y_train,theta,learning_rate,iterations)\n",
    "g = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for index,rows in X_test.iterrows():\n",
    "    y = 0\n",
    "    rows = list(rows)\n",
    "    for i in range(len(rows)):\n",
    "        y = y + rows[i]*g[i+1]\n",
    "    y = y + g[0]\n",
    "#     y_pred.append(y)\n",
    "    if y >= threshold:\n",
    "        y_pred.append(1)\n",
    "    else:\n",
    "        y_pred.append(0)\n",
    "\n",
    "# Vectorized form\n",
    "# ones = np.ones([X_test.shape[0],1])\n",
    "# X_test = np.concatenate((X_test,ones),axis=1)\n",
    "# y_pred = X_test @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  6]\n",
      " [ 0 82]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.25      0.40         8\n",
      "           1       0.93      1.00      0.96        82\n",
      "\n",
      "   micro avg       0.93      0.93      0.93        90\n",
      "   macro avg       0.97      0.62      0.68        90\n",
      "weighted avg       0.94      0.93      0.91        90\n",
      "\n",
      "93.33333333333333\n"
     ]
    }
   ],
   "source": [
    "(y_pred == Y_test).mean()\n",
    "print(confusion_matrix(Y_test,y_pred))\n",
    "print(classification_report(Y_test,y_pred))\n",
    "print(accuracy_score(Y_test, y_pred)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(x, y):   \n",
    "    ans = np.sqrt(np.sum((x - y) ** 2))\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "k=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = []\n",
    "for index,row in X_test_knn.iterrows():\n",
    "    dist= []\n",
    "    for index1,row1 in X_train_knn.iterrows():\n",
    "        dist.append(euclidean_distance(row,row1))\n",
    "        \n",
    "    our = pd.DataFrame(\n",
    "    {'a': dist,\n",
    "     'b': Y_train_knn\n",
    "    })\n",
    "    our = our.sort_values(by=['a'])\n",
    "    zero = 0\n",
    "    one = 0\n",
    "    i = 0\n",
    "    for index,row in our.iterrows():\n",
    "        if i >= k:\n",
    "            break\n",
    "        if row['b'] == 1:\n",
    "            one = one + 1\n",
    "        elif row['b'] == 0:\n",
    "            zero = zero + 1 \n",
    "        i = i + 1\n",
    "    if one >= zero:\n",
    "        pred.append(1)\n",
    "    else:\n",
    "        pred.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4  4]\n",
      " [ 1 81]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.50      0.62         8\n",
      "           1       0.95      0.99      0.97        82\n",
      "\n",
      "   micro avg       0.94      0.94      0.94        90\n",
      "   macro avg       0.88      0.74      0.79        90\n",
      "weighted avg       0.94      0.94      0.94        90\n",
      "\n",
      "94.44444444444444\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(Y_test_knn,pred))\n",
    "print(classification_report(Y_test_knn,pred))\n",
    "print(accuracy_score(Y_test_knn, pred)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
