{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score,mean_absolute_error,mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"AdmissionDataset/data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['Chance of Admit ','Serial No.'],axis=1)\n",
    "Y = df['Chance of Admit ']\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size = 0.2)\n",
    "# Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8045886472085619\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, Y_train) \n",
    "y_pred = lr.predict(X_test)\n",
    "print(r2_score(Y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = (X_train - X_train.mean())/X_train.std()\n",
    "# Y_train = (Y_train - Y_train.mean())/Y_train.std()\n",
    "X_test = (X_test - X_test.mean())/X_test.std()\n",
    "# Y_test = (Y_test - Y_test.mean())/Y_test.std()\n",
    "# X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train,Y_train],axis=1)\n",
    "ones = np.ones([X_train.shape[0],1])\n",
    "Y_train = X_train.iloc[:,7:8].values\n",
    "X_train = X_train.iloc[:,0:7]\n",
    "X_train = np.concatenate((ones,X_train),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "iterations = 1000\n",
    "# theta = np.zeros(8) # 7 is the number of features\n",
    "theta = np.zeros([1,8])\n",
    "# theta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent_mean_absolute(X_train,Y_train,theta,learning_rate,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        p = X_train @ theta.T - Y_train\n",
    "        theta = theta - (learning_rate/len(X_train)) * np.sum((X_train * (p/np.absolute(p))), axis=0)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = gradient_descent_mean_absolute(X_train,Y_train,theta,learning_rate,iterations)\n",
    "g = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for index,rows in X_test.iterrows():\n",
    "    y = 0\n",
    "    rows = list(rows)\n",
    "    for i in range(len(rows)):\n",
    "        y = y + rows[i]*g[i+1]\n",
    "    y = y + g[0]\n",
    "    y_pred.append(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_absolute_percentage_error(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error\n",
      "0.7734825224998861\n",
      "0.04677773137602631\n",
      "0.004357346127433548\n",
      "7.882525484095408\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Absolute Error\")\n",
    "print(r2_score(Y_test,y_pred))\n",
    "print(mean_absolute_error(Y_test,y_pred))\n",
    "print(mean_squared_error(Y_test, y_pred))\n",
    "print(mean_absolute_percentage_error(Y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.004357346127433548\n",
      "0.04677773137602631\n"
     ]
    }
   ],
   "source": [
    "mse = np.sum(np.power((Y_test-y_pred),2))/len(Y_test)\n",
    "print(mse)\n",
    "mae = np.sum(abs(Y_test-y_pred))/len(Y_test)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Difference between MSE and MAE\n",
    "* Both mean squared error (MSE) and mean absolute error (MAE) are used in predictive modeling. Because of the square, large errors have relatively greater influence on MSE than do the smaller error. Therefore, MAE is more robust to outliers since it does not make use of square.\n",
    "\n",
    "## Difference between MAE and MAPE\n",
    "* MAPE is used to normalize – or weight – errors by the inverse of the actual observation value, This could be useful if we are interested in minimizing the relative – rather than absolute - error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_decent_mean_square(X_train,Y_train,theta,learning_rate,iterations):\n",
    "    \n",
    "    for i in range(iterations):\n",
    "        theta = theta - (learning_rate/len(X_train)) * np.sum(X_train * (X_train @ theta.T - Y_train), axis=0)\n",
    "    \n",
    "    return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = np.zeros([1,8])\n",
    "g = gradient_decent_mean_square(X_train,Y_train,theta,learning_rate,iterations)\n",
    "g = g[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = []\n",
    "for index,rows in X_test.iterrows():\n",
    "    y = 0\n",
    "    rows = list(rows)\n",
    "    for i in range(len(rows)):\n",
    "        y = y + rows[i]*g[i+1]\n",
    "    y = y + g[0]\n",
    "    y_pred.append(y)\n",
    "\n",
    "# Vectorized form\n",
    "# ones = np.ones([X_test.shape[0],1])\n",
    "# X_test = np.concatenate((X_test,ones),axis=1)\n",
    "# y_pred = X_test @ g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Square Error\n",
      "0.7845453149965098\n",
      "0.046944040402229756\n",
      "0.0041445395194147925\n",
      "7.814233276803395\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Square Error\")\n",
    "print(r2_score(Y_test,y_pred))\n",
    "print(mean_absolute_error(Y_test,y_pred))\n",
    "print(mean_squared_error(Y_test, y_pred))\n",
    "print(mean_absolute_percentage_error(Y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
